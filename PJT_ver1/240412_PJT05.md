# Web Crawling
웹 크롤링 : 웹 페이지를 자동으로 탐색하고 데이터를 수집하는 기술
- 여러 웹 페이지를 돌아다니며 원하는 정보를 모으는 기술
- 원하는 정보를 추출하는 스크래핑(Scraping)과 여러 웹 페이지를 자동으로 탐색하는 크롤링의 개념을 합쳐 웹 크롤링이라고 부름
- 즉, 웹 사이트들을 돌아다니며 *필요한 데이터를 추출하여 활용할 수 있도록 자동화된 프로세스*
## 웹 크롤링 프로세스
- 웹 페이지 다운로드
	- 해당 웹 페이지의 HTML, CSS, JavaScript 등의 코드를 가져오는 단계
- 페이지 파싱
	- 다운로드 받은 코드를 분석하고 필요한 데이터를 추출하는 단계
- 링크 추출 및 다른 페이지 탐색
	- 다른 링크를 추출하고, 다음 단계로 이동하여 원하는 데이터를 추출하는 단계
- 데이터 추출 및 저장
	- 분석 및 시각화에 사용하기 위해 데이터를 처리하고 저장하는 단계
## 웹 크롤링 실습
### 준비 단계
- `requests` : HTTP 요청을 보내고 응답을 받을 수 있는 모듈
- `BeautifulSoup` : HTML 문서에서 원하는 데이터를 추출하는 데 사용되는 파이썬 라이브러리
- `Selenium` : 웹 애플리케이션을 테스트하고 자동화하기 위한 파이썬 라이브러리
	- 웹 페이지의 동적인 컨텐츠를 가져오기 위해 사용함 (검색 결과 등)
```
pip install requests beautifulsoup4 selenium
```
### 기본 예제 실습
- [Quotes to Scrape](https://quotes.toscrape.com/) 사이트 활용
	- 여러가지 주제에 관한 명언들을 모아 둔 데모 사이트
- requests 및 BeautifulSoup 라이브러리 활용 연습
	- examples/example.py
#### 참고 - BeautifulSoup4 요소 선택 메서드 종류
- `find()`
	- 태그를 사용하여 요소를 검색. 첫 번째로 일치하는 요소를 반환
- `find_all()`
	- 태그를 사용하여 요소를 검색. 모든 일치하는 요소를 리스트로 반환
- `select()`
	- CSS 선택자를 사용하여 요소를 검색. 모든 일치하는 요소를 리스트로 반환
	- `.` : class
	- `#` : id
	- `a` : 태그
- `select_one()`
	- CSS 선택자를 사용하여 요소를 검색. 첫 번째로 일치하는 요소를 반환
- `find_parent()` / `find_next_sibling()` / `find_previous_sibling()`
	- 태그를 사용하여 요소를 검색. 각각 일치하는 요소의 부모/다음 형제 요소/이전 형제 요소를 반환
- [공식문서]([Beautiful Soup Documentation — Beautiful Soup 4.4.0 documentation (beautiful-soup-4.readthedocs.io)](https://beautiful-soup-4.readthedocs.io/en/latest/)) 참고